{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Notebook\n",
    "This notebook performs model evaluation and extracts incorrectly labeled samples.\n",
    "\n",
    "The notebook uses publicly available SQuAD evaluation script from https://github.com/huggingface/evaluate/blob/main/metrics/squad/compute_score.py.\n",
    "\n",
    "Before running, please change file paths in order to correspond to your file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from evaluate import evaluator, load\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model and dataset\n",
    "model_ckpt = '../../models/xlmr-cyrl/'\n",
    "loading_script = \"../finetuning/loading_script.py\"\n",
    "dev_data = \"../../data/squad-sr/squad-sr-v1.1-dev-cyrillic.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline\n",
    "pipe = pipeline('question-answering', model=model_ckpt, tokenizer=model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_files = {\n",
    "    \"dev\": dev_data\n",
    "}\n",
    "dataset = load_dataset(loading_script, data_files=data_files)\n",
    "validation_dataset = dataset['validation'] # Ignore `train` split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(example, max_length, tokenizer):\n",
    "    \"\"\"Exclude examples that have more than `max_length` tokens\n",
    "\n",
    "    This function is forwarded to `Dateset.filter` function\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        example[\"question\"],\n",
    "        example[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"do_not_truncate\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    return len(inputs[\"input_ids\"])==tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training dataset\n",
    "validation_dataset = validation_dataset.filter(filter_dataset, fn_kwargs={\"max_length\": max_length, \"tokenizer\": pipe.tokenizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "squad_evaluator = evaluator('question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "def evaluate_squad():\n",
    "    evaluation_results = squad_evaluator.compute(pipe, data=validation_dataset, squad_v2_format=False)\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_squad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model     | EM    | F1    |\n",
    "|-----------|-------|-------|\n",
    "| bert-cyrl | 51.46 | 67.28 |\n",
    "| bert-lat  | 69.32 | 80.11 |\n",
    "| xlmr-cyrl | 53.73 | 69.45 |\n",
    "| xlmr-lat  | 71.04 | 81.62 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SQuAD metric\n",
    "squad_metric = load('squad')\n",
    "squad_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract wrong answers\n",
    "em_errors = []\n",
    "f1_errors = []\n",
    "\n",
    "for o, m in zip(pipe(question=validation_dataset['question'], context=validation_dataset['context']), validation_dataset):\n",
    "    pred = [{'prediction_text': o['answer'], 'id': m['id']}]\n",
    "    ref = [{\"answers\": m['answers'], \"id\": m['id']}]\n",
    "    res = squad_metric.compute(predictions=pred, references=ref)\n",
    "    if res['exact_match'] == 0.:\n",
    "        em_errors.append({\n",
    "            \"id\": m['id'],\n",
    "            \"question\": m['question'],\n",
    "            \"answers\": m['answers'],\n",
    "            \"prediction\": pred,\n",
    "            \"context\": m['context'],\n",
    "            \"score\": res\n",
    "        })\n",
    "    if res['f1'] <= 50.:\n",
    "        f1_errors.append({\n",
    "            \"id\": m['id'],\n",
    "            \"question\": m['question'],\n",
    "            \"answers\": m['answers'],\n",
    "            \"prediction\": pred,\n",
    "            \"context\": m['context'],\n",
    "            \"score\": res\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save errors to files\n",
    "with open('../data/error_analysis/em_errors.json', 'w') as f:\n",
    "    json.dump(em_errors, f, ensure_ascii=False)\n",
    "\n",
    "with open('../data/error_analysis/f1_errors.json', 'w') as f:\n",
    "    json.dump(f1_errors, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9228a2d60ec10907bce5bff9bcb9ef094edbbac38ba30f1458adf98cbaefdbc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
